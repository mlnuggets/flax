{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## How to load datasets in JAX with TensorFlow\n",
    "Click the image below to read the post online.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://www.machinelearningnuggets.com/how-to-load-dataset-in-jax-with-tensorflow\"><img src=\"https://digitalpress.fra1.cdn.digitaloceanspaces.com/mhujhsj/2022/07/logo.png\" alt=\"Open in ML Nuggets\"></a>"
   ],
   "metadata": {
    "id": "AP4s37C8ZOFt"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FOYfP6vf2FGx",
    "outputId": "ec87cb3e-bb57-4c3f-f950-afc5546d794e",
    "tags": [
     "skip-execution"
    ],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSaA8Mif6srP"
   },
   "source": [
    "## 1. Imports\n",
    "\n",
    "Import JAX, [JAX NumPy](https://jax.readthedocs.io/en/latest/jax.numpy.html),\n",
    "Flax, ordinary NumPy, and TensorFlow Datasets (TFDS). Flax can use any\n",
    "data-loading pipeline and this example demonstrates how to utilize TFDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "inJ9bV636dRx",
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install -q flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Z7MuGFB16E8m"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp                # JAX NumPy\n",
    "from flax import linen as nn           # The Linen API\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "import optax                           # Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0FW1DHa6cfH"
   },
   "source": [
    "## 2. Define network\n",
    "\n",
    "Create a convolutional neural network with the Linen API by subclassing\n",
    "[Module](https://flax.readthedocs.io/en/latest/flax.linen.html#core-module-abstraction).\n",
    "Because the architecture in this example is relatively simple—you're just\n",
    "stacking layers—you can define the inlined submodules directly within the\n",
    "`__call__` method and wrap it with the\n",
    "[@compact](https://flax.readthedocs.io/en/latest/flax.linen.html#compact-methods)\n",
    "decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "_s1lXBBO66dc"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, x):\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "    x = x.reshape((x.shape[0], -1))  # flatten\n",
    "    x = nn.Dense(features=256)(x)\n",
    "    x = nn.relu(x)\n",
    "    x = nn.Dense(features=2)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDEoAprU6_JZ"
   },
   "source": [
    "## 3. Define loss\n",
    "\n",
    "We simply use `optax.softmax_cross_entropy()`. Note that this function expects both `logits` and `labels` to have shape `[batch, num_classes]`. Since the labels will be read from TFDS as integer values, we first need to convert them to a onehot encoding.\n",
    "\n",
    "Our function returns a simple scalar value ready for optimization, so we first take the mean of the vector shaped `[batch]` returned by Optax's loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "Zcb_ebU87G7s"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(*, logits, labels):\n",
    "  labels_onehot = jax.nn.one_hot(labels, num_classes=2)\n",
    "  return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INZE3eM67JUr"
   },
   "source": [
    "## 4. Metric computation\n",
    "\n",
    "For loss and accuracy metrics, create a separate function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "KvuEA8Tw-MYa"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(*, logits, labels):\n",
    "  loss = cross_entropy_loss(logits=logits, labels=labels)\n",
    "  accuracy = jnp.mean(jnp.argmax(logits, -1) == labels)\n",
    "  metrics = {\n",
    "      'loss': loss,\n",
    "      'accuracy': accuracy,\n",
    "  }\n",
    "  return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lYz0Emry-ele"
   },
   "source": [
    "## 5. Loading data\n",
    "\n",
    "Define a function that loads and prepares the MNIST dataset and converts the\n",
    "samples to floating-point numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "IOeWiS_b-p8O"
   },
   "outputs": [],
   "source": [
    "import wget # pip install wget\n",
    "import zipfile\n",
    "\n",
    "wget.download(\"https://ml.machinelearningnuggets.com/train.zip\")\n",
    "with zipfile.ZipFile('train.zip', 'r') as zip_ref:\n",
    "  zip_ref.extractall('.')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import numpy as np"
   ],
   "metadata": {
    "id": "BMPMKXn-ybUD"
   },
   "execution_count": 73,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "base_dir = 'train'\n",
    "filenames = os.listdir(base_dir)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'dog':\n",
    "        categories.append(\"dog\")\n",
    "    else:\n",
    "        categories.append(\"cat\")\n",
    "\n",
    "df = pd.DataFrame({'filename': filenames,'category': categories})"
   ],
   "metadata": {
    "id": "725_teG7ybRM"
   },
   "execution_count": 74,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = df.sample(800)"
   ],
   "metadata": {
    "id": "xrvSZmyTybLu"
   },
   "execution_count": 75,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   validation_split=0.2\n",
    "                                   )\n"
   ],
   "metadata": {
    "id": "HrPz3v6zybGh"
   },
   "execution_count": 76,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "validation_gen = ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
    "image_size = (128, 128)\n",
    "batch_size = 64\n",
    "training_set = train_datagen.flow_from_dataframe(df,base_dir,\n",
    "                                                seed=101,                                                 \n",
    "                                                target_size=image_size,\n",
    "                                                batch_size=batch_size,\n",
    "                                                x_col='filename',\n",
    "                                                y_col='category',\n",
    "                                                subset = \"training\",\n",
    "                                                class_mode='binary')\n",
    "validation_set = validation_gen.flow_from_dataframe(df,base_dir, \n",
    "                                              target_size=image_size,\n",
    "                                              batch_size=batch_size, \n",
    "                                              x_col='filename',\n",
    "                                                y_col='category',\n",
    "                                              subset = \"validation\",\n",
    "                                              class_mode='binary')"
   ],
   "metadata": {
    "id": "pturl2a6yqWC",
    "outputId": "91a3b3ee-aac7-4383-a69f-abc2e21f6cce",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 77,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 640 validated image filenames belonging to 2 classes.\n",
      "Found 160 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train_images, train_labels = next(training_set)\n",
    "test_images, test_labels = next(validation_set)\n",
    "\n",
    "print('Train:', train_images.shape, train_labels.shape)\n",
    "print('Test:', test_images.shape, test_labels.shape)"
   ],
   "metadata": {
    "id": "_fNVdi0TyqT8",
    "outputId": "b2097954-e8af-4748-ac68-8999c7215c0f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": 78,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: (64, 128, 128, 3) (64,)\n",
      "Test: (64, 128, 128, 3) (64,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for train_images, train_labels in training_set:\n",
    "  print('Train:', train_images.shape, train_labels.shape)\n",
    "  break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsolZwsH4chT",
    "outputId": "5d7738a3-7694-4c57-923c-69fed7b73931"
   },
   "execution_count": 79,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: (64, 128, 128, 3) (64,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMFK51rsAUX4"
   },
   "source": [
    "## 6. Create train state\n",
    "\n",
    "A common pattern in Flax is to create a single dataclass that represents the\n",
    "entire training state, including step number, parameters, and optimizer state.\n",
    "\n",
    "Also adding optimizer & model to this state has the advantage that we only need\n",
    "to pass around a single argument to functions like `train_step()` (see below).\n",
    "\n",
    "Because this is such a common pattern, Flax provides the class\n",
    "[flax.training.train_state.TrainState](https://flax.readthedocs.io/en/latest/flax.training.html#train-state)\n",
    "that serves most basic usecases. Usually one would subclass it to add more data\n",
    "to be tracked, but in this example we can use it without any modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "QadyBPbWBEAT"
   },
   "outputs": [],
   "source": [
    "def create_train_state(rng, learning_rate, momentum):\n",
    "  \"\"\"Creates initial `TrainState`.\"\"\"\n",
    "  cnn = CNN()\n",
    "  params = cnn.init(rng, jnp.ones([1, image_size[1], image_size[1], 3]))['params']\n",
    "  tx = optax.sgd(learning_rate, momentum)\n",
    "  return train_state.TrainState.create(\n",
    "      apply_fn=cnn.apply, params=params, tx=tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7l-75YE-sr-"
   },
   "source": [
    "## 7. Training step\n",
    "\n",
    "A function that:\n",
    "\n",
    "- Evaluates the neural network given the parameters and a batch of input images\n",
    "  with the\n",
    "  [Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)\n",
    "  method.\n",
    "- Computes the `cross_entropy_loss` loss function.\n",
    "- Evaluates the loss function and its gradient using\n",
    "  [jax.value_and_grad](https://jax.readthedocs.io/en/latest/jax.html#jax.value_and_grad).\n",
    "- Applies a\n",
    "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)\n",
    "  of gradients to the optimizer to update the model's parameters.\n",
    "- Computes the metrics using `compute_metrics` (defined earlier).\n",
    "\n",
    "Use JAX's [@jit](https://jax.readthedocs.io/en/latest/jax.html#jax.jit)\n",
    "decorator to trace the entire `train_step` function and just-in-time compile\n",
    "it with [XLA](https://www.tensorflow.org/xla) into fused device operations\n",
    "that run faster and more efficiently on hardware accelerators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "Ng11cdMf-z0x"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, train_images, train_labels):\n",
    "  \"\"\"Train for a single step.\"\"\"\n",
    "  def loss_fn(params):\n",
    "    logits = CNN().apply({'params': params}, train_images)\n",
    "    loss = cross_entropy_loss(logits=logits, labels=train_labels)\n",
    "    return loss, logits\n",
    "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "  (_, logits), grads = grad_fn(state.params)\n",
    "  state = state.apply_gradients(grads=grads)\n",
    "  metrics = compute_metrics(logits=logits, labels=train_labels)\n",
    "  return state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-4qDNUgBryr"
   },
   "source": [
    "## 8. Evaluation step\n",
    "\n",
    "Create a function that evaluates your model on the test set with\n",
    "[Module.apply](https://flax.readthedocs.io/en/latest/flax.linen.html#flax.linen.Module.apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "w1J9i6alBv_u"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, test_images, test_labels):\n",
    "  logits = CNN().apply({'params': params}, test_images)\n",
    "  return compute_metrics(logits=logits, labels=test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MBTLQPC4BxgH"
   },
   "source": [
    "## 9. Train function\n",
    "\n",
    "Define a training function that:\n",
    "\n",
    "- Shuffles the training data before each epoch using\n",
    "  [jax.random.permutation](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.permutation.html)\n",
    "  that takes a PRNGKey as a parameter (check the\n",
    "  [JAX - the sharp bits](https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#JAX-PRNG)).\n",
    "- Runs an optimization step for each batch.\n",
    "- Retrieves the training metrics from the device with `jax.device_get` and\n",
    "  computes their mean across each batch in an epoch.\n",
    "- Returns the optimizer with updated parameters and the training loss and\n",
    "  accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(state, train_images, train_labels, epoch):\n",
    "    \"\"\"Train for 1 epoch on the training set.\"\"\"\n",
    "    batch_metrics = []\n",
    "    # for train_images, train_labels in training_set:\n",
    "    state, metrics = train_step(state, train_images, train_labels)\n",
    "    batch_metrics.append(metrics)\n",
    "\n",
    "    batch_metrics_np = jax.device_get(batch_metrics)  \n",
    "    epoch_metrics_np = {\n",
    "        k: np.mean([metrics[k] for metrics in batch_metrics_np])\n",
    "        for k in batch_metrics_np[0]}\n",
    "    print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (epoch, epoch_metrics_np['loss'], epoch_metrics_np['accuracy'] * 100))\n",
    "\n",
    "    return state"
   ],
   "metadata": {
    "id": "g54m9HR92bDR"
   },
   "execution_count": 90,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2cHbVUfCRMv"
   },
   "source": [
    "## 10. Eval function\n",
    "\n",
    "Create a model evaluation function that:\n",
    "\n",
    "- Retrieves the evaluation metrics from the device with `jax.device_get`.\n",
    "- Copies the metrics\n",
    "  [data stored](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
    "  in a JAX\n",
    "  [pytree](https://jax.readthedocs.io/en/latest/pytrees.html#pytrees-and-jax-functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "_dKahNmMCr5q"
   },
   "outputs": [],
   "source": [
    "def eval_model(params, test_images, test_labels ):\n",
    "  metrics = eval_step(params, test_images, test_labels )\n",
    "  metrics = jax.device_get(metrics)\n",
    "  summary = jax.tree_map(lambda x: x.item(), metrics)\n",
    "  return summary['loss'], summary['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56rKPl6OHqu8"
   },
   "source": [
    "## 12. Seed randomness\n",
    "\n",
    "- Get one\n",
    "  [PRNGKey](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.PRNGKey.html#jax.random.PRNGKey)\n",
    "  and\n",
    "  [split](https://jax.readthedocs.io/en/latest/_autosummary/jax.random.split.html#jax.random.split)\n",
    "  it to get a second key that you'll use for parameter initialization. (Learn\n",
    "  more about\n",
    "  [PRNG chains](https://flax.readthedocs.io/en/latest/design_notes/linen_design_principles.html#how-are-parameters-represented-and-how-do-we-handle-general-differentiable-algorithms-that-update-stateful-variables)\n",
    "  and\n",
    "  [JAX PRNG design](https://github.com/google/jax/blob/main/design_notes/prng.md).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "n53xh_B8Ht_W"
   },
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y3iHFiAuH41s"
   },
   "source": [
    "## 13. Initialize train state\n",
    "\n",
    "Remember that function initializes both the model parameters and the optimizer\n",
    "and puts both into the training state dataclass that is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "Mj6OfdEEIU-o"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "_87fL90dH-0Z"
   },
   "outputs": [],
   "source": [
    "state = create_train_state(init_rng, learning_rate, momentum)\n",
    "del init_rng  # Must not be used anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqNrWu7kIC9S"
   },
   "source": [
    "## 14. Train and evaluate\n",
    "\n",
    "Once the training and testing is done after 10 epochs, the output should show that your model was able to achieve approximately 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "0nxgS5Z5IsT_"
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugGlV3u6Iq1A",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5d893377-3a3c-436f-b618-6d5518f5304e",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs + 1):\n",
    "  # Use a separate PRNG key to permute image data during shuffling\n",
    "  # Run an optimization step over a training batch\n",
    "  state = train_epoch(state, train_images, train_labels, epoch)\n",
    "  # Evaluate on the test set after each training epoch \n",
    "  test_loss, test_accuracy = eval_model(state.params, test_images, test_labels)\n",
    "  print(' test epoch: %d, loss: %.2f, accuracy: %.2f' % (\n",
    "      epoch, test_loss, test_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Where to go from here\n",
    "Follow us on [LinkedIn](https://www.linkedin.com/company/mlnuggets), [Twitter](https://twitter.com/ml_nuggets), [GitHub](https://github.com/mlnuggets) and subscribe to our [blog](https://www.machinelearningnuggets.com/#/portal) so that you don't miss a new issue."
   ],
   "metadata": {
    "id": "E28rZVRvcoF7"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "load image  data with tf flax.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "50100d07a2a27af6847cdedde67ae5e97c9798a9e1a9ae21eed9ecf69a9f619c"
  },
  "jupytext": {
   "formats": "ipynb,md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.11"
  },
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}